llm:
  provider: anthropic         # Options: ollama, openai, openrouter, groq, etc.
  model: claude-opus-4-1-20250805 # Model name for the selected provider
  context_length: 60000    # Some models support higher limitsm
# ollama:
#   host: http://host.docker.internal:11434

# Notes:
# - To switch models or providers, edit the values above
# - Providers currently supported: groq, ollama, openai, openrouter
